{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de un interferograma con Stack Sentinel-1 TOPS\n",
    "\n",
    "\n",
    "Los detalles del algoritmo para procesas stacks de datos tipo TOPS se puede encontrar en:\n",
    "\n",
    "> Fattahi, H., P. Agram, and M. Simons (2016), A Network-Based Enhanced Spectral Diversity Approach for TOPS Time-Series Analysis, IEEE Transactions on Geoscience and Remote Sensing, 55(2), 777-786, doi:[10.1109/TGRS.2016.2614925](https://ieeexplore.ieee.org/abstract/document/7637021).\n",
    "\n",
    "## Instalación\n",
    "\n",
    "### 1. Instale ISCE2 \n",
    "La instalación de ISCE2 se debe havcer de la manera usual (Ver los detalles [aquí](../README.md)). \n",
    "### 2. Paths de configuración para procesadores stack\n",
    "Los procesadores de stack no aparecen en el directorio de instalación de su software ISCE. Se pueden encontrar en el directorio fuente de ISCE. Por lo tanto, se necesita una configuración de ruta adicional.\n",
    "#### 2.1 Agregue el siguiente path \n",
    "Agregue el siguiente path a su variable de entorno ${PYTHONPATH}:\n",
    "```\n",
    "export ISCE_STACK={ruta_completa_a_tu_contrib/stack}\n",
    "export PYTHONPATH=${PYTHONPATH}:${ISCE_STACK}\n",
    "export PATH=${PATH}:${ISCE_STACK}/topsStack\n",
    "```\n",
    "\n",
    "## stackSentinel.py\n",
    "\n",
    "Los scripts brindan soporte para el procesamiento de stack de TOPS de Sentinel-1. Los flujos de trabajo admitidos actualmente incluyen una pila registrada de SLC, interferogramas, compensaciones y coherencia.\n",
    "\n",
    "`stackSentinel.py` genera todos los archivos de configuración y ejecución necesarios para ejecutarse en un stack de datos TOPS de Sentinel-1. Cuando se ejecuta stackSentinel.py para un flujo de trabajo determinado (opción -W), se genera una carpeta *configs* y *run_files*. En esta etapa no se realiza ningún procesamiento. Dentro de la carpeta *run_files* se encuentran diferentes archivos *run_#_descripción* que deben ejecutarse como scripts de shell en el orden del número de ejecución. Cada uno de estos scripts de ejecución llama a archivos de configuración específicos contenidos en la carpeta *configs* que llaman a ISCE de forma modular. Los archivos de configuración y ejecución cambiarán según el flujo de trabajo seleccionado. Para hacer que los archivos *run_#* sean ejecutables, cambie el permiso del archivo en consecuencia (por ejemplo, `chmod +x run_01_unpack_slc`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver las diferentes opciones de `stackSentinel.py`, podemos utilizar los siguiente comandos\n",
    "```bash\n",
    "stackSentinel.py -H #Para ver ejemplos de flujo de trabajo,\n",
    "stackSentinel.py -h #Para obtener una descripción general de todos los parámetros configurables\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Open Source version of ISCE.\n",
      "Some of the workflows depend on a separate licensed package.\n",
      "To obtain the licensed package, please make a request for ISCE\n",
      "through the website: https://download.jpl.nasa.gov/ops/request/index.cfm.\n",
      "Alternatively, if you are a member, or can become a member of WinSAR\n",
      "you may be able to obtain access to a version of the licensed sofware at\n",
      "https://winsar.unavco.org/software/isce\n",
      "\n",
      "\n",
      "Stack processor for Sentinel-1 data using ISCE software.\n",
      "\n",
      "For a full list of different options, try stackSentinel.py -h\n",
      "\n",
      "stackSentinel.py generates all configuration and run files required to be executed for a stack of Sentinel-1 TOPS data.\n",
      "\n",
      "Following are required to start processing:\n",
      "\n",
      "1) a folder that includes Sentinel-1 SLCs,\n",
      "2) a DEM (Digital Elevation Model)\n",
      "3) a folder that includes precise orbits (use dloadOrbits.py to download/ update your orbit folder. Missing orbits downloaded on the fly.)\n",
      "4) a folder for Sentinel-1 Aux files (which is used for correcting the Elevation Antenna Pattern).\n",
      "\n",
      "Note that stackSentinel.py does not process any data. It only prepares a lot of input files for processing and a lot of run files. Then you need to execute all those generated run files in order. To know what is really going on, after running stackSentinel.py, look at each run file generated by stackSentinel.py. Each run file actually has several commands that are independent from each other and can be executed in parallel. The config files for each run file include the processing options to execute a specific command/function.\n",
      "\n",
      "Note also that run files need to be executed in order, i.e., running run_03 needs results from run_02, etc.\n",
      "\n",
      "##############################################\n",
      "\n",
      "#Examples:\n",
      "\n",
      "stackSentinel.py can be run for different workflows including: a stack of interferogram, a stack of correlation files, a stack of offsets or a coregistered stack of SLC. Workflow can be chosen with -W option.\n",
      "\n",
      "%%%%%%%%%%%%%%%\n",
      "Example 1:\n",
      "# interferogram workflow with 2 nearest neighbor connections (default coregistration is NESD):\n",
      "\n",
      "stackSentinel.py -s ../SLC/ -d ../../MexicoCity/demLat_N18_N20_Lon_W100_W097.dem.wgs84 -b '19 20 -99.5 -98.5' -a ../../AuxDir/ -o ../../Orbits -c 2\n",
      "\n",
      "%%%%%%%%%%%%%%%\n",
      "Example 2:\n",
      "# interferogram workflow with all possible interferograms and coregistration with only geometry:\n",
      "\n",
      "stackSentinel.py -s ../SLC/ -d ../../MexicoCity/demLat_N18_N20_Lon_W100_W097.dem.wgs84 -b '19 20 -99.5 -98.5' -a ../../AuxDir/ -o ../../Orbits -C geometry -c all\n",
      "\n",
      "%%%%%%%%%%%%%%%\n",
      "Example 3:\n",
      "# correlation workflow with all possible correlation pairs and coregistration with geometry:\n",
      "\n",
      "stackSentinel.py -s ../SLC/ -d ../../MexicoCity/demLat_N18_N20_Lon_W100_W097.dem.wgs84 -b '19 20 -99.5 -98.5' -a ../../AuxDir/ -o ../../Orbits -C geometry -c all -W correlation\n",
      "\n",
      "%%%%%%%%%%%%%%%\n",
      "Example 4:\n",
      "# slc workflow that produces a coregistered stack of SLCs\n",
      "\n",
      "stackSentinel.py -s ../SLC/ -d ../../MexicoCity/demLat_N18_N20_Lon_W100_W097.dem.wgs84 -b '19 20 -99.5 -98.5' -a ../../AuxDir/ -o ../../Orbits -C NESD  -W slc\n",
      "\n",
      "##############################################\n",
      "\n",
      "#Note:\n",
      "\n",
      "For all workflows, coregistration can be done using only geometry or with geometry plus refined azimuth offsets through NESD approach.\n",
      "Existing workflows: slc, interferogram, correlation, offset\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!stackSentinel.py -H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Open Source version of ISCE.\n",
      "Some of the workflows depend on a separate licensed package.\n",
      "To obtain the licensed package, please make a request for ISCE\n",
      "through the website: https://download.jpl.nasa.gov/ops/request/index.cfm.\n",
      "Alternatively, if you are a member, or can become a member of WinSAR\n",
      "you may be able to obtain access to a version of the licensed sofware at\n",
      "https://winsar.unavco.org/software/isce\n",
      "usage: stackSentinel.py [-h] [-H] -s SLC_DIRNAME -o ORBIT_DIRNAME -a\n",
      "                        AUX_DIRNAME [-w WORK_DIR] -d DEM [-m REFERENCE_DATE]\n",
      "                        [-c NUM_CONNECTIONS] [-n SWATH_NUM] [-b BBOX]\n",
      "                        [-x EXCLUDE_DATES] [-i INCLUDE_DATES]\n",
      "                        [--start_date STARTDATE] [--stop_date STOPDATE]\n",
      "                        [-z AZIMUTHLOOKS] [-r RANGELOOKS] [-f FILTSTRENGTH]\n",
      "                        [--snr_misreg_threshold SNRTHRESHOLD]\n",
      "                        [-p POLARIZATION] [-C {geometry,NESD}]\n",
      "                        [-O NUM_OVERLAP_CONNECTIONS]\n",
      "                        [-e ESDCOHERENCETHRESHOLD]\n",
      "                        [-W {slc,correlation,interferogram,offset}]\n",
      "                        [-u {icu,snaphu}] [-rmFilter] [--param_ion PARAM_ION]\n",
      "                        [--num_connections_ion NUM_CONNECTIONS_ION] [-useGPU]\n",
      "                        [--num_proc NUMPROCESS]\n",
      "                        [--num_proc4topo NUMPROCESS4TOPO] [-t TEXT_CMD]\n",
      "                        [-V {True,False}]\n",
      "\n",
      "Preparing the directory structure and config files for stack processing of\n",
      "Sentinel data\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -H, --hh              Display detailed help information.\n",
      "  -s SLC_DIRNAME, --slc_directory SLC_DIRNAME\n",
      "                        Directory with all Sentinel SLCs\n",
      "  -o ORBIT_DIRNAME, --orbit_directory ORBIT_DIRNAME\n",
      "                        Directory with all orbits\n",
      "  -a AUX_DIRNAME, --aux_directory AUX_DIRNAME\n",
      "                        Directory with all aux files\n",
      "  -w WORK_DIR, --working_directory WORK_DIR\n",
      "                        Working directory (default: ./).\n",
      "  -d DEM, --dem DEM     Path of the DEM file\n",
      "  -m REFERENCE_DATE, --reference_date REFERENCE_DATE\n",
      "                        Directory with reference acquisition\n",
      "  -c NUM_CONNECTIONS, --num_connections NUM_CONNECTIONS\n",
      "                        number of interferograms between each date and\n",
      "                        subsequent dates (default: 1).\n",
      "  -n SWATH_NUM, --swath_num SWATH_NUM\n",
      "                        A list of swaths to be processed. -- Default : '1 2 3'\n",
      "  -b BBOX, --bbox BBOX  Lat/Lon Bounding SNWE. -- Example : '19 20 -99.5\n",
      "                        -98.5' -- Default : common overlap between stack\n",
      "  -x EXCLUDE_DATES, --exclude_dates EXCLUDE_DATES\n",
      "                        List of the dates to be excluded for processing. --\n",
      "                        Example : '20141007,20141031' (default: None).\n",
      "  -i INCLUDE_DATES, --include_dates INCLUDE_DATES\n",
      "                        List of the dates to be included for processing. --\n",
      "                        Example : '20141007,20141031' (default: None).\n",
      "  --start_date STARTDATE\n",
      "                        Start date for stack processing. Acquisitions before\n",
      "                        start date are ignored. format should be YYYY-MM-DD\n",
      "                        e.g., 2015-01-23\n",
      "  --stop_date STOPDATE  Stop date for stack processing. Acquisitions after\n",
      "                        stop date are ignored. format should be YYYY-MM-DD\n",
      "                        e.g., 2017-02-26\n",
      "  -z AZIMUTHLOOKS, --azimuth_looks AZIMUTHLOOKS\n",
      "                        Number of looks in azimuth for interferogram multi-\n",
      "                        looking (default: 3).\n",
      "  -r RANGELOOKS, --range_looks RANGELOOKS\n",
      "                        Number of looks in range for interferogram multi-\n",
      "                        looking (default: 9).\n",
      "  -f FILTSTRENGTH, --filter_strength FILTSTRENGTH\n",
      "                        Filter strength for interferogram filtering (default:\n",
      "                        0.5).\n",
      "  --snr_misreg_threshold SNRTHRESHOLD\n",
      "                        SNR threshold for estimating range misregistration\n",
      "                        using cross correlation (default: 10).\n",
      "  -p POLARIZATION, --polarization POLARIZATION\n",
      "                        SAR data polarization (default: vv).\n",
      "  -C {geometry,NESD}, --coregistration {geometry,NESD}\n",
      "                        Coregistration options (default: NESD).\n",
      "  -O NUM_OVERLAP_CONNECTIONS, --num_overlap_connections NUM_OVERLAP_CONNECTIONS\n",
      "                        number of overlap interferograms between each date and\n",
      "                        subsequent dates used for NESD computation (for\n",
      "                        azimuth offsets misregistration) (default: 3).\n",
      "  -e ESDCOHERENCETHRESHOLD, --esd_coherence_threshold ESDCOHERENCETHRESHOLD\n",
      "                        Coherence threshold for estimating azimuth\n",
      "                        misregistration using enhanced spectral diversity\n",
      "                        (default: 0.85).\n",
      "  -W {slc,correlation,interferogram,offset}, --workflow {slc,correlation,interferogram,offset}\n",
      "                        The InSAR processing workflow (default:\n",
      "                        interferogram).\n",
      "  -u {icu,snaphu}, --unw_method {icu,snaphu}\n",
      "                        Unwrapping method (default: snaphu).\n",
      "  -rmFilter, --rmFilter\n",
      "                        Make an extra unwrap file in which filtering effect is\n",
      "                        removed\n",
      "  --param_ion PARAM_ION\n",
      "                        ionosphere estimation parameter file. if provided,\n",
      "                        will do ionosphere estimation.\n",
      "  --num_connections_ion NUM_CONNECTIONS_ION\n",
      "                        number of interferograms between each date and\n",
      "                        subsequent dates for ionosphere estimation (default:\n",
      "                        3).\n",
      "\n",
      "Computing options:\n",
      "  -useGPU, --useGPU     Allow App to use GPU when available\n",
      "  --num_proc NUMPROCESS, --num_process NUMPROCESS\n",
      "                        number of tasks running in parallel in each run file\n",
      "                        (default: 1).\n",
      "  --num_proc4topo NUMPROCESS4TOPO, --num_process4topo NUMPROCESS4TOPO\n",
      "                        number of parallel processes (for topo only) (default:\n",
      "                        1).\n",
      "  -t TEXT_CMD, --text_cmd TEXT_CMD\n",
      "                        text command to be added to the beginning of each line\n",
      "                        of the run files (default: ''). Example : 'source\n",
      "                        ~/.bash_profile;'\n",
      "  -V {True,False}, --virtual_merge {True,False}\n",
      "                        Use virtual files for the merged SLCs and geometry\n",
      "                        files. Default: True for correlation / interferogram\n",
      "                        workflow False for slc / offset workflow\n"
     ]
    }
   ],
   "source": [
    "!stackSentinel.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros requeridos de `stackSentinel.py` incluyen:\n",
    "```cfg\n",
    "-s SLC_DIRNAME   #Una carpeta con Sentinel-1 SLC descargados.\n",
    "-o ORBIT_DIRNAME #Una carpeta que contiene las órbitas de Sentinel-1. Los archivos de órbita faltantes se descargarán automáticamente\n",
    "-a AUX_DIRNAME   #Una carpeta que contiene los archivos auxiliares de Sentinel-1\n",
    "-d DEM_FILENAME  #Un DEM (Modelo de elevación digital) con referencia a wgs84\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.- Configuración inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma que en el caso de topsApp.py, utilizaremos la siguiente estructura de directorios\n",
    "\n",
    "```\n",
    ".\n",
    "├── Interferograma_StackSentinel.ipynb    (Este cuaderno)\n",
    "├── stackproc                             (Aquí es donde procesaremos el interferograma)\n",
    "└── data                                 (Aquí es donde descargaremos los datos para este portátil)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio del notebook:  /Users/javjrg/Library/CloudStorage/OneDrive-Personal/Proyectos/Gits/InSAR/Notebooks\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile, move # Utilidades para copiar y mover archivos\n",
    "from osgeo import gdal            # Soporte GDAL para leer archivos virtuales\n",
    "import os                         # Para crear y eliminar directorios\n",
    "import matplotlib.pyplot as plt   # Para graficar\n",
    "import numpy as np                # Cálculos de matrices\n",
    "import glob                       # Recuperando lista de archivos\n",
    "import boto3                      # Para hablar con el cubo s3\n",
    "\n",
    "# directorio en el que reside el portátil\n",
    "if 'tutorial_home_dir' not in globals():\n",
    "    tutorial_home_dir = os.getcwd()\n",
    "print(\"Directorio del notebook: \", tutorial_home_dir)\n",
    "# directorio para descargas de datos\n",
    "slc_dir = os.path.join(tutorial_home_dir,'data', 'slcs')\n",
    "orbit_dir = os.path.join(tutorial_home_dir, 'data', 'orbits')\n",
    "\n",
    "# definición de directorios de respaldo en caso de problemas de descarga en el servidor local\n",
    "s3 = boto3.resource(\"s3\")\n",
    "data_backup_bucket = s3.Bucket(\"asf-jupyter-data\")\n",
    "data_backup_dir = \"TOPS\"\n",
    "\n",
    "# generar todas las carpetas en caso de que aún no existan\n",
    "os.makedirs(slc_dir, exist_ok=True)\n",
    "os.makedirs(orbit_dir, exist_ok=True)\n",
    "os.makedirs(insar_dir, exist_ok=True)\n",
    "\n",
    "# Comience siempre en el directorio del notebook  \n",
    "os.chdir(tutorial_home_dir)\n",
    "\n",
    "# Utilidad para copiar datos de\n",
    "def copy_from_bucket(file_in_bucket, dest_file,\n",
    "                    bucket=data_backup_bucket):\n",
    "    if os.path.exists(dest_file):\n",
    "        print(\"Destination file {0} already exists. Skipping download...\".format(dest_file))\n",
    "    else:\n",
    "        bucket.download_file(file_in_bucket, dest_file)\n",
    "\n",
    "# Utilidad para graficar una matriz 2D\n",
    "def plotdata(GDALfilename, band=1,\n",
    "             title=None,colormap='gray',\n",
    "             aspect=1, background=None,\n",
    "             datamin=None, datamax=None,\n",
    "             interpolation='nearest',\n",
    "             nodata = None,\n",
    "             draw_colorbar=True, colorbar_orientation=\"horizontal\"):\n",
    "    # Leer los datos en una matriz\n",
    "    ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "    data = ds.GetRasterBand(band).ReadAsArray()\n",
    "    transform = ds.GetGeoTransform()\n",
    "    ds = None\n",
    "    try:\n",
    "        if nodata is not None:\n",
    "            data[data == nodata] = np.nan\n",
    "    except:\n",
    "        pass\n",
    "    # obteniendo el min max de los ejes\n",
    "    firstx = transform[0]\n",
    "    firsty = transform[3]\n",
    "    deltay = transform[5]\n",
    "    deltax = transform[1]\n",
    "    lastx = firstx+data.shape[1]*deltax\n",
    "    lasty = firsty+data.shape[0]*deltay\n",
    "    ymin = np.min([lasty,firsty])\n",
    "    ymax = np.max([lasty,firsty])\n",
    "    xmin = np.min([lastx,firstx])\n",
    "    xmax = np.max([lastx,firstx])\n",
    "    # poner todos los valores cero en nan y no trazar nan\n",
    "    if background is None:\n",
    "        try:\n",
    "            data[data==0]=np.nan\n",
    "        except:\n",
    "            pass\n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.imshow(data, vmin = datamin, vmax=datamax,\n",
    "                    cmap=colormap, extent=[xmin,xmax,ymin,ymax],\n",
    "                    interpolation=interpolation)\n",
    "    ax.set_title(title)\n",
    "    if draw_colorbar is not None:\n",
    "        cbar = fig.colorbar(cax,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)    \n",
    "    plt.show()\n",
    "    # borrando los datos\n",
    "    data = None\n",
    "\n",
    "# Utilidad para trazar interferogramas\n",
    "def plotcomplexdata(GDALfilename,\n",
    "                    title=None, aspect=1,\n",
    "                    datamin=None, datamax=None,\n",
    "                    interpolation='nearest',\n",
    "                    draw_colorbar=None, colorbar_orientation=\"horizontal\"):\n",
    "    # Cargue los datos en una matriz numpy\n",
    "    ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "    slc = ds.GetRasterBand(1).ReadAsArray()\n",
    "    transform = ds.GetGeoTransform()\n",
    "    ds = None\n",
    "    # obteniendo el min max de los ejes\n",
    "    firstx = transform[0]\n",
    "    firsty = transform[3]\n",
    "    deltay = transform[5]\n",
    "    deltax = transform[1]\n",
    "    lastx = firstx+slc.shape[1]*deltax\n",
    "    lasty = firsty+slc.shape[0]*deltay\n",
    "    ymin = np.min([lasty,firsty])\n",
    "    ymax = np.max([lasty,firsty])\n",
    "    xmin = np.min([lastx,firstx])\n",
    "    xmax = np.max([lastx,firstx])\n",
    "    # poner todos los valores cero en nan y no trazar nan\n",
    "    try:\n",
    "        slc[slc==0]=np.nan\n",
    "    except:\n",
    "        pass\n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    cax1=ax.imshow(np.abs(slc), vmin = datamin, vmax=datamax,\n",
    "                   cmap='gray', extent=[xmin,xmax,ymin,ymax],\n",
    "                   interpolation=interpolation)\n",
    "    ax.set_title(title + \" (amplitude)\")\n",
    "    if draw_colorbar is not None:\n",
    "        cbar1 = fig.colorbar(cax1,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)\n",
    "\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    cax2 =ax.imshow(np.angle(slc), cmap='rainbow',\n",
    "                    vmin=-np.pi, vmax=np.pi,\n",
    "                    extent=[xmin,xmax,ymin,ymax],\n",
    "                    interpolation=interpolation)\n",
    "    ax.set_title(title + \" (phase [rad])\")\n",
    "    if draw_colorbar is not None:\n",
    "        cbar2 = fig.colorbar(cax2, orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)\n",
    "    plt.show()\n",
    "    # borrando los datos\n",
    "    slc = None\n",
    "\n",
    "# Utilidad para trazar múltiples matrices similares\n",
    "def plotstackdata(GDALfilename_wildcard, band=1,\n",
    "                  title=None, colormap='gray',\n",
    "                  aspect=1, datamin=None, datamax=None,\n",
    "                  interpolation='nearest',\n",
    "                  draw_colorbar=True, colorbar_orientation=\"horizontal\"):\n",
    "    # obtener una lista de todos los archivos que coincidan con los criterios de comodín de nombre de archivo\n",
    "    GDALfilenames = glob.glob(GDALfilename_wildcard)\n",
    "    # inicializar matriz numpy vacía\n",
    "    data = None\n",
    "    for GDALfilename in GDALfilenames:\n",
    "        ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "        data_temp = ds.GetRasterBand(band).ReadAsArray()   \n",
    "        ds = None\n",
    "        if data is None:\n",
    "            data = data_temp\n",
    "        else:\n",
    "            data = np.vstack((data,data_temp))\n",
    "    # poner todos los valores cero en nan y no trazar nan\n",
    "    try:\n",
    "        data[data==0]=np.nan\n",
    "    except:\n",
    "        pass            \n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.imshow(data, vmin = datamin, vmax=datamax,\n",
    "                    cmap=colormap, interpolation=interpolation)\n",
    "    ax.set_title(title)\n",
    "    if draw_colorbar is not None:\n",
    "        cbar = fig.colorbar(cax,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)    \n",
    "    plt.show() \n",
    "    # borrando los datos\n",
    "    data = None\n",
    "\n",
    "# Utilidad para trazar múltiples matrices complejas simples\n",
    "def plotstackcomplexdata(GDALfilename_wildcard,\n",
    "                         title=None, aspect=1,\n",
    "                         datamin=None, datamax=None,\n",
    "                         interpolation='nearest',\n",
    "                         draw_colorbar=True, colorbar_orientation=\"horizontal\"):\n",
    "    # obtener una lista de todos los archivos que coincidan con los criterios de comodín de nombre de archivo\n",
    "    GDALfilenames = glob.glob(GDALfilename_wildcard)\n",
    "    print(GDALfilenames)\n",
    "    # inicializar matriz numpy vacía\n",
    "    data = None\n",
    "    for GDALfilename in GDALfilenames:\n",
    "        ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "        data_temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "        ds = None\n",
    "        if data is None:\n",
    "            data = data_temp\n",
    "        else:\n",
    "            data = np.vstack((data,data_temp))\n",
    "    # poner todos los valores cero en nan y no trazar nan\n",
    "    try:\n",
    "        data[data==0]=np.nan\n",
    "    except:\n",
    "        pass              \n",
    "            \n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    cax1=ax.imshow(np.abs(data), vmin=datamin, vmax=datamax,\n",
    "                   cmap='gray', interpolation='nearest')\n",
    "    ax.set_title(title + \" (amplitude)\")\n",
    "    if draw_colorbar is not None:\n",
    "        cbar1 = fig.colorbar(cax1,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)\n",
    "\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    cax2 =ax.imshow(np.angle(data), cmap='rainbow',\n",
    "                            interpolation='nearest')\n",
    "    ax.set_title(title + \" (phase [rad])\")\n",
    "    if draw_colorbar is not None:\n",
    "        cbar2 = fig.colorbar(cax2,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)\n",
    "    plt.show() \n",
    "    # borrando los datos\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Descarga de archivos SLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1A_IW_SLC__1SDV_20200511T135117_20200511T135144_032518_03C421_7768.zip ya existe. Saltando descarga...\n",
      "S1B_IW_SLC__1SDV_20200517T135026_20200517T135056_021622_0290CB_99E2.zip ya existe. Saltando descarga...\n"
     ]
    }
   ],
   "source": [
    "# Actualice esto con su inicio de sesión de NASA Earthdata para descargar datos SLC\n",
    "ASF_USER = \"user\"\n",
    "ASF_PASS = \"pass\"\n",
    "\n",
    "files = ['https://datapool.asf.alaska.edu/SLC/SA/S1A_IW_SLC__1SDV_20200511T135117_20200511T135144_032518_03C421_7768.zip',\n",
    "         'https://datapool.asf.alaska.edu/SLC/SB/S1B_IW_SLC__1SDV_20200517T135026_20200517T135056_021622_0290CB_99E2.zip']\n",
    "         \n",
    "if len(ASF_USER)==0 or len(ASF_PASS)==0:\n",
    "    raise Exception(\"Especifique su contraseña y usuario de ASF (inicio de sesión de Earthdata)\")\n",
    "    \n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(slc_dir,filename)):\n",
    "        cmd = \"wget {0} --user={1} --password={2} -P {3} -nc\".format(file, ASF_USER, ASF_PASS, slc_dir)\n",
    "        print(cmd)\n",
    "        os.system(cmd)\n",
    "    else:\n",
    "        print(filename + \" ya existe. Saltando descarga...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b10a308d3382843c8b8a9afe74ca556f8226380fcadce398aff78111941f1e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
